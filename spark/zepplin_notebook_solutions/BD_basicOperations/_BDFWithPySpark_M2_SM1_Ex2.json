{"paragraphs":[{"text":"%md\n\n# RDDs from External Datasets\n\n- PySpark can easily create RDDs from files that are stored in external storage devices such as `HDFS` (Hadoop Distributed File System), Amazon `S3 buckets`, etc. However, the most common method of creating RDD's is from files stored in your local file system. This method takes a file path and reads it as a collection of lines. In this exercise, you'll create an RDD from the file path (`file_path`) with the file name `README.md` which is already available in your workspace.\n\n- Remember you already have a `SparkContext` `sc` available in your workspace.\n\n## Instructions\n- Print the `file_path` in the PySpark shell.\n- Create an RDD named `fileRDD` from a `file_path` with the file name `README.md`.\n- Print the type of the `fileRDD` created.","user":"anonymous","dateUpdated":"2021-02-26T12:14:47+0530","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>RDDs from External Datasets</h1>\n<ul>\n  <li>\n  <p>PySpark can easily create RDDs from files that are stored in external storage devices such as <code>HDFS</code> (Hadoop Distributed File System), Amazon <code>S3 buckets</code>, etc. However, the most common method of creating RDD&rsquo;s is from files stored in your local file system. This method takes a file path and reads it as a collection of lines. In this exercise, you&rsquo;ll create an RDD from the file path (<code>file_path</code>) with the file name <code>README.md</code> which is already available in your workspace.</p></li>\n  <li>\n  <p>Remember you already have a <code>SparkContext</code> <code>sc</code> available in your workspace.</p></li>\n</ul>\n<h2>Instructions</h2>\n<ul>\n  <li>Print the <code>file_path</code> in the PySpark shell.</li>\n  <li>Create an RDD named <code>fileRDD</code> from a <code>file_path</code> with the file name <code>README.md</code>.</li>\n  <li>Print the type of the <code>fileRDD</code> created.</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1614321685536_-400708007","id":"20201113-110338_1928025495","dateCreated":"2021-02-26T12:11:25+0530","dateStarted":"2021-02-26T12:14:47+0530","dateFinished":"2021-02-26T12:14:47+0530","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5891"},{"text":"%pyspark\n\nfile_path = \"file:////home/talentum/spark/README.md\"\n\n# Print the file_path\nprint(\"The file_path is\", ____)\n\n# Create a fileRDD from file_path\nfileRDD = sc.____(file_path)\n\n# Check the type of fileRDD\nprint(\"The file type of fileRDD is\", type(____))\n","user":"anonymous","dateUpdated":"2021-02-26T12:11:25+0530","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1614321685542_-2047054053","id":"20201113-133413_165094595","dateCreated":"2021-02-26T12:11:25+0530","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5892"},{"text":"%pyspark\n\nfile_path = \"file:////home/talentum/spark/README.md\"\nprint(\"The file_path is\", file_path)\n\nfileRDD = sc.textFile(file_path)\n\nprint(type(fileRDD))","user":"anonymous","dateUpdated":"2021-02-26T12:16:17+0530","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"The file_path is file:////home/talentum/spark/README.md\n<class 'pyspark.rdd.RDD'>\n"}]},"apps":[],"jobName":"paragraph_1614321910387_944259886","id":"20210226-121510_124177029","dateCreated":"2021-02-26T12:15:10+0530","dateStarted":"2021-02-26T12:16:17+0530","dateFinished":"2021-02-26T12:16:18+0530","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5893"},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-02-26T12:16:17+0530","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1614321977693_1420337556","id":"20210226-121617_1484744537","dateCreated":"2021-02-26T12:16:17+0530","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:5894"}],"name":"/BDFWithPySpark/M2/SM1/Ex2","id":"2G1MA6A99","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}