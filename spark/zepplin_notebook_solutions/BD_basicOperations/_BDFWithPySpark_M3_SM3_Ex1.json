{"paragraphs":[{"text":"%md\n\n# Running SQL Queries Programmatically\n\n- DataFrames can easily be manipulated using SQL queries in PySpark. The `sql()` function on a SparkSession enables applications to run SQL queries programmatically and returns the result as another DataFrame. In this exercise, you'll create a temporary table of the `people_df` DataFrame that you created previously, then construct a query to select the names of the people from the temporary table and assign the result to a new DataFrame.\n\n- Remember, you already have `SparkSession` `spark` and `people_df` DataFrame available in your workspace.\n\n## Instructions\n- Create a temporary table `people` that's a pointer to the `people_df` DataFrame.\n- Construct a query to select the names of the people from the temporary table `people`.\n- Assign the result of Spark's query to a new DataFrame - `people_df_names`.\n- Print the top 10 names of the people from `people_df_names` DataFrame.","user":"anonymous","dateUpdated":"2021-03-01T14:50:26+0530","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Running SQL Queries Programmatically</h1>\n<ul>\n  <li>\n  <p>DataFrames can easily be manipulated using SQL queries in PySpark. The <code>sql()</code> function on a SparkSession enables applications to run SQL queries programmatically and returns the result as another DataFrame. In this exercise, you&rsquo;ll create a temporary table of the <code>people_df</code> DataFrame that you created previously, then construct a query to select the names of the people from the temporary table and assign the result to a new DataFrame.</p></li>\n  <li>\n  <p>Remember, you already have <code>SparkSession</code> <code>spark</code> and <code>people_df</code> DataFrame available in your workspace.</p></li>\n</ul>\n<h2>Instructions</h2>\n<ul>\n  <li>Create a temporary table <code>people</code> that&rsquo;s a pointer to the <code>people_df</code> DataFrame.</li>\n  <li>Construct a query to select the names of the people from the temporary table <code>people</code>.</li>\n  <li>Assign the result of Spark&rsquo;s query to a new DataFrame - <code>people_df_names</code>.</li>\n  <li>Print the top 10 names of the people from <code>people_df_names</code> DataFrame.</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1614590403557_770489235","id":"20201113-110338_1928025495","dateCreated":"2021-03-01T14:50:03+0530","dateStarted":"2021-03-01T14:50:26+0530","dateFinished":"2021-03-01T14:50:26+0530","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4988"},{"text":"%pyspark\n\nfile_path = \"file:////home/talentum/BigDataFundamentalsWithPySpark/Dataset/people.csv\"\n\n# Create an DataFrame from file_path\n# people_df = spark.read.csv(file_path, header=True, inferSchema=True)\n\n# Create a temporary table \"people\"\npeople_df.____(\"people\")\n\n# Construct a query to select the names of the people from the temporary table \"people\"\nquery = '''SELECT name FROM ____'''\n\n# Assign the result of Spark's query to people_df_names\npeople_df_names = spark.sql(____)\n\n# Print the top 10 names of the people\npeople_df_names.____(____)\n","user":"anonymous","dateUpdated":"2021-03-01T14:50:03+0530","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1614590403579_-1932899509","id":"20201113-133413_165094595","dateCreated":"2021-03-01T14:50:03+0530","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4989"},{"text":"%pyspark\n\nfile_path = \"file:////home/talentum/shared_BDVM/spark/DataSet/people.csv\"\npeople_df = spark.read.csv(file_path, header=True, inferSchema=True)\n\npeople_df.createOrReplaceTempView(\"people\")\n\nquery = '''select name from people'''\n\npeople_df_names = spark.sql(query)\nprint(people_df_names.show(10))","user":"anonymous","dateUpdated":"2021-03-01T14:55:10+0530","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------------+\n|            name|\n+----------------+\n|  Penelope Lewis|\n|   David Anthony|\n|       Ida Shipp|\n|    Joanna Moore|\n|  Lisandra Ortiz|\n|   David Simmons|\n|   Edward Hudson|\n|    Albert Jones|\n|Leonard Cavender|\n|  Everett Vadala|\n+----------------+\nonly showing top 10 rows\n\nNone\n"}]},"apps":[],"jobName":"paragraph_1614590443437_1607978636","id":"20210301-145043_2013500728","dateCreated":"2021-03-01T14:50:43+0530","dateStarted":"2021-03-01T14:55:10+0530","dateFinished":"2021-03-01T14:55:16+0530","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4990"},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-03-01T14:55:10+0530","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1614590710590_-1938401005","id":"20210301-145510_475254936","dateCreated":"2021-03-01T14:55:10+0530","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:4991"}],"name":"/BDFWithPySpark/M3/SM3/Ex1","id":"2G2EENCWK","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}