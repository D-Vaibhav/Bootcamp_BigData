{"paragraphs":[{"text":"%md\n\n# Loading CSV into DataFrame\n\n- In the previous exercise, you have seen a method of creating DataFrame but generally, loading data from CSV file is the most common method of creating DataFrames. In this exercise, you'll create a PySpark DataFrame from a `people.csv` file that is already provided to you as a `file_path` and confirm the created object is a PySpark DataFrame.\n\n- Remember, you already have `SparkSession` `spark` and `file_path` variable (which is the path to the `people.csv` file) available in your workspace..\n\n## Instructions\n- Create a DataFrame from `file_path` variable which is the path to the `people.csv` file.\n- Confirm the output as PySpark DataFrame.","user":"anonymous","dateUpdated":"2021-03-01T11:27:00+0530","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Loading CSV into DataFrame</h1>\n<ul>\n  <li>\n  <p>In the previous exercise, you have seen a method of creating DataFrame but generally, loading data from CSV file is the most common method of creating DataFrames. In this exercise, you&rsquo;ll create a PySpark DataFrame from a <code>people.csv</code> file that is already provided to you as a <code>file_path</code> and confirm the created object is a PySpark DataFrame.</p></li>\n  <li>\n  <p>Remember, you already have <code>SparkSession</code> <code>spark</code> and <code>file_path</code> variable (which is the path to the <code>people.csv</code> file) available in your workspace..</p></li>\n</ul>\n<h2>Instructions</h2>\n<ul>\n  <li>Create a DataFrame from <code>file_path</code> variable which is the path to the <code>people.csv</code> file.</li>\n  <li>Confirm the output as PySpark DataFrame.</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1614577935901_227168897","id":"20201113-110338_1928025495","dateCreated":"2021-03-01T11:22:15+0530","dateStarted":"2021-03-01T11:27:00+0530","dateFinished":"2021-03-01T11:27:01+0530","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1556"},{"text":"%pyspark\n\n# file_path = \"/home/talentum/BigDataFundamentalsWithPySpark/Dataset/people.csv\"\n\n# Create an DataFrame from file_path\npeople_df = ____(file_path, header=True, inferSchema=True)\n\n# Check the type of people_df\nprint(\"The type of people_df is\", ____(people_df))","user":"anonymous","dateUpdated":"2021-03-01T11:34:54+0530","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1614577935903_-1529983523","id":"20201113-133413_165094595","dateCreated":"2021-03-01T11:22:15+0530","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1557"},{"text":"%pyspark\n\n# using host machine storage\nfile_path = \"file:////home/talentum/shared_BDVM/spark/DataSet/people.csv\"\n\npeople_df = spark.read.csv(file_path, header=True, inferSchema=True)\nprint(\"The type of people_df is\", type(people_df))\nprint(people_df.printSchema())","user":"anonymous","dateUpdated":"2021-03-01T12:29:19+0530","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"The type of people_df is <class 'pyspark.sql.dataframe.DataFrame'>\nroot\n |-- _c0: integer (nullable = true)\n |-- person_id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- sex: string (nullable = true)\n |-- date of birth: string (nullable = true)\n\nNone\n"}]},"apps":[],"jobName":"paragraph_1614578276461_1098697788","id":"20210301-112756_1382519919","dateCreated":"2021-03-01T11:27:56+0530","dateStarted":"2021-03-01T11:42:05+0530","dateFinished":"2021-03-01T11:42:07+0530","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1558"},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-03-01T11:29:46+0530","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1614578386263_357682304","id":"20210301-112946_186194603","dateCreated":"2021-03-01T11:29:46+0530","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:1559"}],"name":"/BDFWithPySpark/M3/SM1/Ex2","id":"2FYD41WP7","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}