{"paragraphs":[{"text":"%md\n\n# PySpark DataFrame subsetting and cleaning\n\n- After data inspection, it is often necessary to clean the data which mainly involves subsetting, renaming the columns, removing duplicated rows etc., PySpark DataFrame API provides several operators to do this. In this exercise, your job is to subset `'name'`, `'sex'` and `'date of birth'` columns from `people_df` DataFrame, remove any duplicate rows from that dataset and count the number of rows before and after duplicates removal step.\n\n- Remember, you already have `SparkSession` `spark` and `people_df` DataFrames available in your workspace.\n\n## Instructions\n- Select `'name'`, `'sex'` and `'date of birth'` columns from `people_df` and create `people_df_sub` DataFrame.\n- Print the first 10 observations in the `people_df` DataFrame.\n- Remove duplicate entries from `people_df_sub` DataFrame and create `people_df_sub_nodup` DataFrame.\n- How many rows are there before and after duplicates are removed?","user":"anonymous","dateUpdated":"2021-03-01T12:39:11+0530","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>PySpark DataFrame subsetting and cleaning</h1>\n<ul>\n  <li>\n  <p>After data inspection, it is often necessary to clean the data which mainly involves subsetting, renaming the columns, removing duplicated rows etc., PySpark DataFrame API provides several operators to do this. In this exercise, your job is to subset <code>&#39;name&#39;</code>, <code>&#39;sex&#39;</code> and <code>&#39;date of birth&#39;</code> columns from <code>people_df</code> DataFrame, remove any duplicate rows from that dataset and count the number of rows before and after duplicates removal step.</p></li>\n  <li>\n  <p>Remember, you already have <code>SparkSession</code> <code>spark</code> and <code>people_df</code> DataFrames available in your workspace.</p></li>\n</ul>\n<h2>Instructions</h2>\n<ul>\n  <li>Select <code>&#39;name&#39;</code>, <code>&#39;sex&#39;</code> and <code>&#39;date of birth&#39;</code> columns from <code>people_df</code> and create <code>people_df_sub</code> DataFrame.</li>\n  <li>Print the first 10 observations in the <code>people_df</code> DataFrame.</li>\n  <li>Remove duplicate entries from <code>people_df_sub</code> DataFrame and create <code>people_df_sub_nodup</code> DataFrame.</li>\n  <li>How many rows are there before and after duplicates are removed?</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1614582097500_-162748391","id":"20201113-110338_1928025495","dateCreated":"2021-03-01T12:31:37+0530","dateStarted":"2021-03-01T12:39:11+0530","dateFinished":"2021-03-01T12:39:11+0530","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3245"},{"text":"%pyspark\n\nfile_path = \"file:////home/talentum/BigDataFundamentalsWithPySpark/Dataset/people.csv\"\n\n# Create an DataFrame from file_path\n# people_df = spark.read.csv(file_path, header=True, inferSchema=True)\n\n# Select name, sex and date of birth columns\npeople_df_sub = people_df.____('name', ____, ____)\n\n# Print the first 10 observations from people_df_sub\npeople_df_sub.____(____)\n\n# Remove duplicate entries from people_df_sub\npeople_df_sub_nodup = people_df_sub.____()\n\n# Count the number of rows\nprint(\"There were {} rows before removing duplicates, and {} rows after removing duplicates\".format(people_df_sub.____(), people_df_sub_nodup.____()))","user":"anonymous","dateUpdated":"2021-03-01T12:31:37+0530","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1614582097510_-1706803648","id":"20201113-133413_165094595","dateCreated":"2021-03-01T12:31:37+0530","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3246"},{"text":"%pyspark\n\nfile_path = \"file:////home/talentum/shared_BDVM/spark/DataSet/people.csv\"\n\npeople_df = spark.read.csv(file_path, header=True, inferSchema=True)\n\npeople_df_sub = people_df.select('name','sex','date of birth')\nprint(people_df_sub.show(10))\n\npeople_df_sub_nodup = people_df_sub.dropDuplicates()\nprint(\"There were {} rows before removing duplicates, and {} rows after removing duplicates\".format(people_df_sub.count(), people_df_sub_nodup.count()))","user":"anonymous","dateUpdated":"2021-03-01T12:44:29+0530","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------------+------+-------------+\n|            name|   sex|date of birth|\n+----------------+------+-------------+\n|  Penelope Lewis|female|   1990-08-31|\n|   David Anthony|  male|   1971-10-14|\n|       Ida Shipp|female|   1962-05-24|\n|    Joanna Moore|female|   2017-03-10|\n|  Lisandra Ortiz|female|   2020-08-05|\n|   David Simmons|  male|   1999-12-30|\n|   Edward Hudson|  male|   1983-05-09|\n|    Albert Jones|  male|   1990-09-13|\n|Leonard Cavender|  male|   1958-08-08|\n|  Everett Vadala|  male|   2005-05-24|\n+----------------+------+-------------+\nonly showing top 10 rows\n\nNone\nThere were 100000 rows before removing duplicates, and 99998 rows after removing duplicates\n"}]},"apps":[],"jobName":"paragraph_1614582505104_66966901","id":"20210301-123825_1970874303","dateCreated":"2021-03-01T12:38:25+0530","dateStarted":"2021-03-01T12:44:29+0530","dateFinished":"2021-03-01T12:44:44+0530","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3247"},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-03-01T12:42:59+0530","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1614582779067_-1029498891","id":"20210301-124259_367814910","dateCreated":"2021-03-01T12:42:59+0530","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:3248"}],"name":"/BDFWithPySpark/M3/SM2/Ex2","id":"2FYZTWQVK","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}